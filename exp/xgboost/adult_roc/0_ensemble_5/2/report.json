{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/archive/xgboost____714e90a0d92e416599c3d7e6f7e3810d.py",
    "config": {
        "seeds": [
            "10",
            "11",
            "12",
            "13",
            "14"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 19775
            },
            "1": {
                "precision": 0.24082463144963145,
                "recall": 1.0,
                "f1-score": 0.3881686828996628,
                "support": 6273
            },
            "accuracy": 0.24082463144963145,
            "macro avg": {
                "precision": 0.12041231572481573,
                "recall": 0.5,
                "f1-score": 0.1940843414498314,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.05799650311285082,
                "recall": 0.24082463144963145,
                "f1-score": 0.09348057999960013,
                "support": 26048
            },
            "roc_auc": 0.945885029312106,
            "score": 0.945885029312106
        },
        "val": {
            "0": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 4945
            },
            "1": {
                "precision": 0.24074927068939045,
                "recall": 1.0,
                "f1-score": 0.38807078331889616,
                "support": 1568
            },
            "accuracy": 0.24074927068939045,
            "macro avg": {
                "precision": 0.12037463534469522,
                "recall": 0.5,
                "f1-score": 0.19403539165944808,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.057960211337473394,
                "recall": 0.24074927068939045,
                "f1-score": 0.09342775805988472,
                "support": 6513
            },
            "roc_auc": 0.9294604811085202,
            "score": 0.9294604811085202
        },
        "test": {
            "0": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 12435
            },
            "1": {
                "precision": 0.23622627602727106,
                "recall": 1.0,
                "f1-score": 0.3821732001788642,
                "support": 3846
            },
            "accuracy": 0.23622627602727106,
            "macro avg": {
                "precision": 0.11811313801363553,
                "recall": 0.5,
                "f1-score": 0.1910866000894321,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.055802853485712456,
                "recall": 0.23622627602727106,
                "f1-score": 0.09027935187567789,
                "support": 16281
            },
            "roc_auc": 0.9269902818629835,
            "score": 0.9269902818629835
        }
    }
}
