{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/archive/catboost____930f7950ef4a48b98ff0e7ea06be7f0f.py",
    "config": {
        "seeds": [
            "5",
            "6",
            "7",
            "8",
            "9"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9045262348645012,
                "recall": 0.9519595448798989,
                "f1-score": 0.9276369280804199,
                "support": 19775
            },
            "1": {
                "precision": 0.8185637891520244,
                "recall": 0.6832456559859716,
                "f1-score": 0.7448084108089321,
                "support": 6273
            },
            "accuracy": 0.8872466216216216,
            "macro avg": {
                "precision": 0.8615450120082628,
                "recall": 0.8176026004329353,
                "f1-score": 0.8362226694446759,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8838243605572851,
                "recall": 0.8872466216216216,
                "f1-score": 0.8836073177900312,
                "support": 26048
            },
            "roc_auc": 0.9414843378894114,
            "score": 0.9414843378894114
        },
        "val": {
            "0": {
                "precision": 0.895576923076923,
                "recall": 0.9417593528816987,
                "f1-score": 0.9180877279448003,
                "support": 4945
            },
            "1": {
                "precision": 0.7806549885757806,
                "recall": 0.6536989795918368,
                "f1-score": 0.7115584866365846,
                "support": 1568
            },
            "accuracy": 0.8724090280976509,
            "macro avg": {
                "precision": 0.8381159558263518,
                "recall": 0.7977291662367677,
                "f1-score": 0.8148231072906924,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8679095511595591,
                "recall": 0.8724090280976509,
                "f1-score": 0.8683659637238144,
                "support": 6513
            },
            "roc_auc": 0.930634943562865,
            "score": 0.930634943562865
        },
        "test": {
            "0": {
                "precision": 0.8982856268176947,
                "recall": 0.9438681141938078,
                "f1-score": 0.9205129210619191,
                "support": 12435
            },
            "1": {
                "precision": 0.7828926905132193,
                "recall": 0.6544461778471139,
                "f1-score": 0.7129301798612095,
                "support": 3846
            },
            "accuracy": 0.8754990479700264,
            "macro avg": {
                "precision": 0.840589158665457,
                "recall": 0.7991571460204608,
                "f1-score": 0.8167215504615644,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8710267831946366,
                "recall": 0.8754990479700264,
                "f1-score": 0.8714764231405427,
                "support": 16281
            },
            "roc_auc": 0.9277992518976996,
            "score": 0.9277992518976996
        }
    }
}
