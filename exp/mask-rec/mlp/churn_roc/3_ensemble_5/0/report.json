{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_ae_mask___d4e106bbfacf424aa229127994b48f79.py",
    "config": {
        "seeds": [
            "0",
            "1",
            "2",
            "3",
            "4"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9038956266078647,
                "recall": 0.9652668759811617,
                "f1-score": 0.9335737331561966,
                "support": 5096
            },
            "1": {
                "precision": 0.8152400835073069,
                "recall": 0.5989263803680982,
                "f1-score": 0.6905393457117596,
                "support": 1304
            },
            "accuracy": 0.890625,
            "macro avg": {
                "precision": 0.8595678550575858,
                "recall": 0.78209662817463,
                "f1-score": 0.812056539433978,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.885832059701126,
                "recall": 0.890625,
                "f1-score": 0.8840554767143927,
                "support": 6400
            },
            "roc_auc": 0.9159886317670061,
            "score": 0.9159886317670061
        },
        "val": {
            "0": {
                "precision": 0.8862144420131292,
                "recall": 0.9536891679748822,
                "f1-score": 0.9187145557655955,
                "support": 1274
            },
            "1": {
                "precision": 0.74235807860262,
                "recall": 0.5214723926380368,
                "f1-score": 0.6126126126126127,
                "support": 326
            },
            "accuracy": 0.865625,
            "macro avg": {
                "precision": 0.8142862603078747,
                "recall": 0.7375807803064596,
                "f1-score": 0.7656635841891041,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.856903707968238,
                "recall": 0.865625,
                "f1-score": 0.8563462848481752,
                "support": 1600
            },
            "roc_auc": 0.8731062977338175,
            "score": 0.8731062977338175
        },
        "test": {
            "0": {
                "precision": 0.8772437753329473,
                "recall": 0.9510357815442562,
                "f1-score": 0.9126506024096386,
                "support": 1593
            },
            "1": {
                "precision": 0.7142857142857143,
                "recall": 0.47911547911547914,
                "f1-score": 0.5735294117647058,
                "support": 407
            },
            "accuracy": 0.855,
            "macro avg": {
                "precision": 0.7957647448093308,
                "recall": 0.7150756303298677,
                "f1-score": 0.7430900070871722,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8440818099098354,
                "recall": 0.855,
                "f1-score": 0.8436394401133949,
                "support": 2000
            },
            "roc_auc": 0.8561442798730935,
            "score": 0.8561442798730935
        }
    }
}
