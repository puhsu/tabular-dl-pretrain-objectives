{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/augmented_supervised___593358efce1f480f9ae1569a6df8e905.py",
    "config": {
        "seeds": [
            "10",
            "11",
            "12",
            "13",
            "14"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7815091210613598,
                "recall": 0.764654181596917,
                "f1-score": 0.7729897823189693,
                "support": 29582
            },
            "1": {
                "precision": 0.794066317626527,
                "recall": 0.8093400464288945,
                "f1-score": 0.8016304347826086,
                "support": 33169
            },
            "accuracy": 0.7882742904495545,
            "macro avg": {
                "precision": 0.7877877193439434,
                "recall": 0.7869971140129057,
                "f1-score": 0.787310108550789,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7881466193142965,
                "recall": 0.7882742904495545,
                "f1-score": 0.7881286932776226,
                "support": 62751
            },
            "roc_auc": 0.8745036948728118,
            "score": 0.8745036948728118
        },
        "val": {
            "0": {
                "precision": 0.7315407597097738,
                "recall": 0.6952406706327745,
                "f1-score": 0.7129289428076256,
                "support": 7396
            },
            "1": {
                "precision": 0.7396928051738076,
                "recall": 0.7724312590448625,
                "f1-score": 0.7557076278685624,
                "support": 8292
            },
            "accuracy": 0.7360402855685875,
            "macro avg": {
                "precision": 0.7356167824417907,
                "recall": 0.7338359648388185,
                "f1-score": 0.7343182853380941,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7358495792525943,
                "recall": 0.7360402855685875,
                "f1-score": 0.735539910204699,
                "support": 15688
            },
            "roc_auc": 0.8199595656978897,
            "score": 0.8199595656978897
        },
        "test": {
            "0": {
                "precision": 0.7232922732362822,
                "recall": 0.6986479177934019,
                "f1-score": 0.7107565337001375,
                "support": 9245
            },
            "1": {
                "precision": 0.7391385767790262,
                "recall": 0.7616015436565364,
                "f1-score": 0.7502019482062248,
                "support": 10365
            },
            "accuracy": 0.7319224885262621,
            "macro avg": {
                "precision": 0.7312154250076541,
                "recall": 0.7301247307249692,
                "f1-score": 0.7304792409531811,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7316679456595633,
                "recall": 0.7319224885262621,
                "f1-score": 0.7316056780833906,
                "support": 19610
            },
            "roc_auc": 0.8139959827570058,
            "score": 0.8139959827570058
        }
    }
}
