{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_mask_supervised___5d613101cea64a948db9a9fbd5ea6666.py",
    "config": {
        "seeds": [
            "5",
            "6",
            "7",
            "8",
            "9"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8986071085494717,
                "recall": 0.9460935524652339,
                "f1-score": 0.9217391304347826,
                "support": 19775
            },
            "1": {
                "precision": 0.796097934200459,
                "recall": 0.6634783994898773,
                "f1-score": 0.7237631510303452,
                "support": 6273
            },
            "accuracy": 0.8780328624078624,
            "macro avg": {
                "precision": 0.8473525213749653,
                "recall": 0.8047859759775555,
                "f1-score": 0.8227511407325638,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8739203744166647,
                "recall": 0.8780328624078624,
                "f1-score": 0.8740616381588292,
                "support": 26048
            },
            "roc_auc": 0.9338723157440544,
            "score": 0.9338723157440544
        },
        "val": {
            "0": {
                "precision": 0.8889529298751201,
                "recall": 0.9356926188068756,
                "f1-score": 0.9117241379310345,
                "support": 4945
            },
            "1": {
                "precision": 0.7568807339449541,
                "recall": 0.6313775510204082,
                "f1-score": 0.6884561891515993,
                "support": 1568
            },
            "accuracy": 0.8624289881774911,
            "macro avg": {
                "precision": 0.8229168319100371,
                "recall": 0.7835350849136419,
                "f1-score": 0.8000901635413169,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8571566450265864,
                "recall": 0.8624289881774911,
                "f1-score": 0.8579725420940691,
                "support": 6513
            },
            "roc_auc": 0.9205923964631353,
            "score": 0.9205923964631353
        },
        "test": {
            "0": {
                "precision": 0.8907254361799817,
                "recall": 0.9360675512665863,
                "f1-score": 0.9128337842606753,
                "support": 12435
            },
            "1": {
                "precision": 0.7525676937441643,
                "recall": 0.6287051482059283,
                "f1-score": 0.6850828729281768,
                "support": 3846
            },
            "accuracy": 0.8634604754007739,
            "macro avg": {
                "precision": 0.821646564962073,
                "recall": 0.7823863497362573,
                "f1-score": 0.7989583285944261,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8580889471800336,
                "recall": 0.8634604754007739,
                "f1-score": 0.859033034614782,
                "support": 16281
            },
            "roc_auc": 0.9160835094441173,
            "score": 0.9160835094441173
        }
    }
}
