{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_ae___efb459f8fdce4cfb860a128f001b0d9f.py",
    "config": {
        "seeds": [
            "10",
            "11",
            "12",
            "13",
            "14"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7723467650397275,
                "recall": 0.7360557095531066,
                "f1-score": 0.7537646692283726,
                "support": 29582
            },
            "1": {
                "precision": 0.7740675366764085,
                "recall": 0.806506074949501,
                "f1-score": 0.7899539333805812,
                "support": 33169
            },
            "accuracy": 0.7732944494908448,
            "macro avg": {
                "precision": 0.773207150858068,
                "recall": 0.7712808922513038,
                "f1-score": 0.7718593013044769,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7732563326070504,
                "recall": 0.7732944494908448,
                "f1-score": 0.7728936345462897,
                "support": 62751
            },
            "roc_auc": 0.8612323899478747,
            "score": 0.8612323899478747
        },
        "val": {
            "0": {
                "precision": 0.7395031236379486,
                "recall": 0.688209843158464,
                "f1-score": 0.7129350794873591,
                "support": 7396
            },
            "1": {
                "precision": 0.7381033503691085,
                "recall": 0.7837674867342016,
                "f1-score": 0.7602503363163128,
                "support": 8292
            },
            "accuracy": 0.7387174910759816,
            "macro avg": {
                "precision": 0.7388032370035285,
                "recall": 0.7359886649463327,
                "f1-score": 0.736592707901836,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7387632638760145,
                "recall": 0.7387174910759816,
                "f1-score": 0.7379438830076092,
                "support": 15688
            },
            "roc_auc": 0.8198151446643172,
            "score": 0.8198151446643172
        },
        "test": {
            "0": {
                "precision": 0.7255639097744361,
                "recall": 0.688912925905895,
                "f1-score": 0.7067635798701658,
                "support": 9245
            },
            "1": {
                "precision": 0.7344903988183161,
                "recall": 0.7675832127351664,
                "f1-score": 0.7506722649431523,
                "support": 10365
            },
            "accuracy": 0.7304946455889852,
            "macro avg": {
                "precision": 0.7300271542963761,
                "recall": 0.7282480693205307,
                "f1-score": 0.7287179224066591,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7302820667830957,
                "recall": 0.7304946455889852,
                "f1-score": 0.7299718165239906,
                "support": 19610
            },
            "roc_auc": 0.8123653390041214,
            "score": 0.8123653390041214
        }
    }
}
