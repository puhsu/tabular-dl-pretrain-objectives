seed = 12
bins = "__none__"

[data]
path = "data/microsoft"
T_cache = true

[data.T]
seed = 0
normalization = "quantile"
num_nan_policy = "__none__"
cat_nan_policy = "__none__"
cat_min_frequency = "__none__"
cat_encoding = "__none__"
y_policy = "default"

[model]
kind = "mlp"
default = true
checkpoint = "__none__"
num_embedding_arch = [
    "positional",
    "linear",
    "relu",
]
d_num_embedding = 53
d_cat_embedding = "__none__"

[model.config]
d_layers = [
    512,
    512,
    512,
    512,
    512,
]
dropout = 0.11178919077725914

[model.positional_encoding]
n = 91
sigma = 0.14781075963965756
trainable = true
initialization = "normal"

[training]
batch_size = 1024
lr = 0.00010778109224350278
weight_decay = 0.0
optimizer = "AdamW"
patience = 16
n_epochs = inf
eval_batch_size = 1024

[pretrain]
corrupt_probability = 0.2469692377701381
corrupt_strategy = "resample"
d_hidden_head = 512
lr = 0.00010778109224350278
weight_decay = 0.0
loss_masked = false
patience = 2
n_iterations = 100000
validate_every = 10000
replace_strategy = "shuffle"
n_neighbors = 20
use_target = false
early_stop_type = "pretrain"
