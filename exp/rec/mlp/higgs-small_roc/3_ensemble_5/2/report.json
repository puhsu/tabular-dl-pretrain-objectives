{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_ae___1c62bf1fc65a492ca9aa6fc84ee89c13.py",
    "config": {
        "seeds": [
            "10",
            "11",
            "12",
            "13",
            "14"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7656932628190388,
                "recall": 0.7879791765262659,
                "f1-score": 0.7766763848396501,
                "support": 29582
            },
            "1": {
                "precision": 0.8058685155379472,
                "recall": 0.7849498025264554,
                "f1-score": 0.7952716220963085,
                "support": 33169
            },
            "accuracy": 0.786377906328186,
            "macro avg": {
                "precision": 0.785780889178493,
                "recall": 0.7864644895263606,
                "f1-score": 0.7859740034679793,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7869291468277951,
                "recall": 0.786377906328186,
                "f1-score": 0.7865054779945975,
                "support": 62751
            },
            "roc_auc": 0.8717825545139348,
            "score": 0.8717825545139348
        },
        "val": {
            "0": {
                "precision": 0.7186618299072954,
                "recall": 0.7232287723093564,
                "f1-score": 0.7209380686030056,
                "support": 7396
            },
            "1": {
                "precision": 0.751728320194057,
                "recall": 0.7474674384949349,
                "f1-score": 0.7495918243937836,
                "support": 8292
            },
            "accuracy": 0.7360402855685875,
            "macro avg": {
                "precision": 0.7351950750506762,
                "recall": 0.7353481054021457,
                "f1-score": 0.7352649464983946,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.736139350143006,
                "recall": 0.7360402855685875,
                "f1-score": 0.736083207755041,
                "support": 15688
            },
            "roc_auc": 0.819158776585406,
            "score": 0.819158776585406
        },
        "test": {
            "0": {
                "precision": 0.7074456865640161,
                "recall": 0.7255813953488373,
                "f1-score": 0.7163987825065414,
                "support": 9245
            },
            "1": {
                "precision": 0.7495063191153238,
                "recall": 0.7323685479980704,
                "f1-score": 0.7408383350412335,
                "support": 10365
            },
            "accuracy": 0.7291687914329423,
            "macro avg": {
                "precision": 0.72847600283967,
                "recall": 0.7289749716734538,
                "f1-score": 0.7286185587738875,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7296771223821855,
                "recall": 0.7291687914329423,
                "f1-score": 0.7293164756234248,
                "support": 19610
            },
            "roc_auc": 0.8119889944552237,
            "score": 0.8119889944552237
        }
    }
}
