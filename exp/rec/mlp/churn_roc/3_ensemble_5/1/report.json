{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_ae___7ccad288b65e4c38b127980fd7c55697.py",
    "config": {
        "seeds": [
            "5",
            "6",
            "7",
            "8",
            "9"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9002205071664829,
                "recall": 0.9613422291993721,
                "f1-score": 0.9297779464794078,
                "support": 5096
            },
            "1": {
                "precision": 0.7943632567849687,
                "recall": 0.5835889570552147,
                "f1-score": 0.6728558797524314,
                "support": 1304
            },
            "accuracy": 0.884375,
            "macro avg": {
                "precision": 0.8472918819757258,
                "recall": 0.7724655931272935,
                "f1-score": 0.8013169131159197,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8786520924012493,
                "recall": 0.884375,
                "f1-score": 0.8774300753837864,
                "support": 6400
            },
            "roc_auc": 0.9111898933122092,
            "score": 0.9111898933122092
        },
        "val": {
            "0": {
                "precision": 0.8839416058394161,
                "recall": 0.9505494505494505,
                "f1-score": 0.9160363086232981,
                "support": 1274
            },
            "1": {
                "precision": 0.7260869565217392,
                "recall": 0.5122699386503068,
                "f1-score": 0.6007194244604317,
                "support": 326
            },
            "accuracy": 0.86125,
            "macro avg": {
                "precision": 0.8050142811805776,
                "recall": 0.7314096945998787,
                "f1-score": 0.7583778665418649,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8517787210409395,
                "recall": 0.86125,
                "f1-score": 0.851790493475114,
                "support": 1600
            },
            "roc_auc": 0.8682522560699598,
            "score": 0.8682522560699598
        },
        "test": {
            "0": {
                "precision": 0.8785425101214575,
                "recall": 0.9535467671060891,
                "f1-score": 0.9145093317278747,
                "support": 1593
            },
            "1": {
                "precision": 0.7269372693726938,
                "recall": 0.48402948402948404,
                "f1-score": 0.5811209439528023,
                "support": 407
            },
            "accuracy": 0.858,
            "macro avg": {
                "precision": 0.8027398897470757,
                "recall": 0.7187881255677866,
                "f1-score": 0.7478151378403386,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8476908436290841,
                "recall": 0.858,
                "f1-score": 0.8466647948156475,
                "support": 2000
            },
            "roc_auc": 0.8561751273615679,
            "score": 0.8561751273615679
        }
    }
}
