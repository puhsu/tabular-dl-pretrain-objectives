seed = 0
program = "bin/finetune_ddp.py"
n_trials = 100

[base_config]
seed = 0

[base_config.data]
T_cache = true
path = "data/weather-small"

[base_config.data.T]
normalization = "quantile"

[base_config.training]
batch_size = 1024

[base_config.model]
kind = "mlp"
num_embedding_arch = [
    "linear",
    "relu",
]

[space.model]
d_num_embedding = [
    "int",
    1,
    128,
]

[space.model.config]
d_layers = [
    "$fixed_mlp_d_layers",
    1,
    8,
    512,
]
dropout = [
    "?uniform",
    0.0,
    0.0,
    0.5,
]

[space.training]
lr = [
    "loguniform",
    5e-05,
    0.005,
]
weight_decay = [
    "?loguniform",
    0.0,
    1e-06,
    0.001,
]

[space.bins]
count = [
    "int",
    2,
    256,
]

[space.bins.tree]
min_samples_leaf = [
    "int",
    1,
    128,
]
min_impurity_decrease = [
    "loguniform",
    1e-09,
    0.01,
]
