{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/finetune___274d6da8626d4547904a645f618bdc95.py",
    "config": {
        "seeds": [
            "5",
            "6",
            "7",
            "8",
            "9"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8789594761989028,
                "recall": 0.9746860282574569,
                "f1-score": 0.9243509816693032,
                "support": 5096
            },
            "1": {
                "precision": 0.8277703604806409,
                "recall": 0.4754601226993865,
                "f1-score": 0.6039941548952752,
                "support": 1304
            },
            "accuracy": 0.87296875,
            "macro avg": {
                "precision": 0.8533649183397718,
                "recall": 0.7250730754784217,
                "f1-score": 0.7641725682822892,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.868529693871307,
                "recall": 0.87296875,
                "f1-score": 0.859078278214095,
                "support": 6400
            },
            "roc_auc": 0.8900859630071944,
            "score": 0.8900859630071944
        },
        "val": {
            "0": {
                "precision": 0.8749121574139143,
                "recall": 0.9772370486656201,
                "f1-score": 0.9232480533926586,
                "support": 1274
            },
            "1": {
                "precision": 0.8361581920903954,
                "recall": 0.4539877300613497,
                "f1-score": 0.5884691848906561,
                "support": 326
            },
            "accuracy": 0.870625,
            "macro avg": {
                "precision": 0.8555351747521549,
                "recall": 0.7156123893634849,
                "f1-score": 0.7558586191416574,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8670160369792472,
                "recall": 0.870625,
                "f1-score": 0.8550368589353755,
                "support": 1600
            },
            "roc_auc": 0.8748374762835761,
            "score": 0.8748374762835761
        },
        "test": {
            "0": {
                "precision": 0.8659966499162479,
                "recall": 0.9736346516007532,
                "f1-score": 0.9166666666666666,
                "support": 1593
            },
            "1": {
                "precision": 0.7990430622009569,
                "recall": 0.4103194103194103,
                "f1-score": 0.5422077922077922,
                "support": 407
            },
            "accuracy": 0.859,
            "macro avg": {
                "precision": 0.8325198560586025,
                "recall": 0.6919770309600818,
                "f1-score": 0.7294372294372294,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8523715948161862,
                "recall": 0.859,
                "f1-score": 0.8404642857142858,
                "support": 2000
            },
            "roc_auc": 0.8626484728179643,
            "score": 0.8626484728179643
        }
    }
}
