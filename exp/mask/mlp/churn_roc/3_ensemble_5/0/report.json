{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_mask___b44a634b009a42cf92bbbfc0cdbafadd.py",
    "config": {
        "seeds": [
            "0",
            "1",
            "2",
            "3",
            "4"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8954951668794455,
                "recall": 0.9635007849293563,
                "f1-score": 0.928254088288118,
                "support": 5096
            },
            "1": {
                "precision": 0.797164667393675,
                "recall": 0.5605828220858896,
                "f1-score": 0.6582620441242684,
                "support": 1304
            },
            "accuracy": 0.88140625,
            "macro avg": {
                "precision": 0.8463299171365603,
                "recall": 0.762041803507623,
                "f1-score": 0.7932580662061932,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8754603276092198,
                "recall": 0.88140625,
                "f1-score": 0.8732432092897336,
                "support": 6400
            },
            "roc_auc": 0.9074291998536083,
            "score": 0.9074291998536083
        },
        "val": {
            "0": {
                "precision": 0.8827785817655571,
                "recall": 0.957613814756672,
                "f1-score": 0.9186746987951807,
                "support": 1274
            },
            "1": {
                "precision": 0.7522935779816514,
                "recall": 0.5030674846625767,
                "f1-score": 0.6029411764705882,
                "support": 326
            },
            "accuracy": 0.865,
            "macro avg": {
                "precision": 0.8175360798736042,
                "recall": 0.7303406497096243,
                "f1-score": 0.7608079376328845,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8561922622445863,
                "recall": 0.865,
                "f1-score": 0.8543439936215449,
                "support": 1600
            },
            "roc_auc": 0.8745991081661548,
            "score": 0.8745991081661548
        },
        "test": {
            "0": {
                "precision": 0.8793302540415704,
                "recall": 0.9560577526679221,
                "f1-score": 0.9160902255639097,
                "support": 1593
            },
            "1": {
                "precision": 0.7388059701492538,
                "recall": 0.4864864864864865,
                "f1-score": 0.5866666666666667,
                "support": 407
            },
            "accuracy": 0.8605,
            "macro avg": {
                "precision": 0.8090681120954121,
                "recall": 0.7212721195772043,
                "f1-score": 0.7513784461152881,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8507335622694839,
                "recall": 0.8605,
                "f1-score": 0.8490525313283208,
                "support": 2000
            },
            "roc_auc": 0.8586876552978246,
            "score": 0.8586876552978246
        }
    }
}
