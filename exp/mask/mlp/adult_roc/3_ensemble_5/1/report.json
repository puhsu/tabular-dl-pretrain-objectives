{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_mask___815b4711a3844c62a9945292c6a7ba3b.py",
    "config": {
        "seeds": [
            "5",
            "6",
            "7",
            "8",
            "9"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9019911825977424,
                "recall": 0.9414917825537295,
                "f1-score": 0.9213182897862232,
                "support": 19775
            },
            "1": {
                "precision": 0.7860181246532273,
                "recall": 0.6775067750677507,
                "f1-score": 0.7277397260273973,
                "support": 6273
            },
            "accuracy": 0.8779176904176904,
            "macro avg": {
                "precision": 0.8440046536254848,
                "recall": 0.80949927881074,
                "f1-score": 0.8245290079068103,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8740620136601678,
                "recall": 0.8779176904176904,
                "f1-score": 0.874699803512455,
                "support": 26048
            },
            "roc_auc": 0.9347269567586729,
            "score": 0.9347269567586729
        },
        "val": {
            "0": {
                "precision": 0.8905491946438968,
                "recall": 0.9280080889787664,
                "f1-score": 0.9088928500693206,
                "support": 4945
            },
            "1": {
                "precision": 0.7382352941176471,
                "recall": 0.6403061224489796,
                "f1-score": 0.6857923497267759,
                "support": 1568
            },
            "accuracy": 0.8587440503608168,
            "macro avg": {
                "precision": 0.814392244380772,
                "recall": 0.784157105713873,
                "f1-score": 0.7973425998980483,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8538797341763458,
                "recall": 0.8587440503608168,
                "f1-score": 0.8551815673214148,
                "support": 6513
            },
            "roc_auc": 0.9166448277996738,
            "score": 0.9166448277996738
        },
        "test": {
            "0": {
                "precision": 0.891473465300778,
                "recall": 0.9307599517490953,
                "f1-score": 0.910693209536549,
                "support": 12435
            },
            "1": {
                "precision": 0.7389326864766526,
                "recall": 0.6336453458138326,
                "f1-score": 0.6822508398656214,
                "support": 3846
            },
            "accuracy": 0.860573674835698,
            "macro avg": {
                "precision": 0.8152030758887152,
                "recall": 0.782202648781464,
                "f1-score": 0.7964720247010852,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8554393251768553,
                "recall": 0.860573674835698,
                "f1-score": 0.8567291192623405,
                "support": 16281
            },
            "roc_auc": 0.9130756376214034,
            "score": 0.9130756376214034
        }
    }
}
