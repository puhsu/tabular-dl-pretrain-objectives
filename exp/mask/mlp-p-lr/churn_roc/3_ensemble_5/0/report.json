{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_mask___f6d1a7dbfc4d4ceabba35c9a3613655a.py",
    "config": {
        "seeds": [
            "0",
            "1",
            "2",
            "3",
            "4"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.897037307973665,
                "recall": 0.9625196232339089,
                "f1-score": 0.9286255206361227,
                "support": 5096
            },
            "1": {
                "precision": 0.7950643776824035,
                "recall": 0.5682515337423313,
                "f1-score": 0.6627906976744186,
                "support": 1304
            },
            "accuracy": 0.8821875,
            "macro avg": {
                "precision": 0.8460508428280342,
                "recall": 0.76538557848812,
                "f1-score": 0.7957081091552707,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8762603234268204,
                "recall": 0.8821875,
                "f1-score": 0.8744616754576755,
                "support": 6400
            },
            "roc_auc": 0.8983364493744642,
            "score": 0.8983364493744642
        },
        "val": {
            "0": {
                "precision": 0.8841951930080116,
                "recall": 0.9529042386185244,
                "f1-score": 0.9172648281072913,
                "support": 1274
            },
            "1": {
                "precision": 0.73568281938326,
                "recall": 0.5122699386503068,
                "f1-score": 0.6039783001808319,
                "support": 326
            },
            "accuracy": 0.863125,
            "macro avg": {
                "precision": 0.8099390061956357,
                "recall": 0.7325870886344156,
                "f1-score": 0.7606215641440616,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8539357968819684,
                "recall": 0.863125,
                "f1-score": 0.8534326980422752,
                "support": 1600
            },
            "roc_auc": 0.8779988635378646,
            "score": 0.8779988635378646
        },
        "test": {
            "0": {
                "precision": 0.8841001747233547,
                "recall": 0.9529190207156308,
                "f1-score": 0.9172205438066464,
                "support": 1593
            },
            "1": {
                "precision": 0.734982332155477,
                "recall": 0.5110565110565111,
                "f1-score": 0.6028985507246376,
                "support": 407
            },
            "accuracy": 0.863,
            "macro avg": {
                "precision": 0.8095412534394159,
                "recall": 0.731987765886071,
                "f1-score": 0.760059547265642,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8537546937607915,
                "recall": 0.863,
                "f1-score": 0.8532560182144576,
                "support": 2000
            },
            "roc_auc": 0.8661141881480864,
            "score": 0.8661141881480864
        }
    }
}
