{
    "program": "bin/ensemble.py",
    "single_program": "/slot/sandbox/d/in/script/0_script_unpacked/pretrains/bin/pretrain_ae_supervised___bc3c28302e004a3280aff5965c005eff.py",
    "config": {
        "seeds": [
            "5",
            "6",
            "7",
            "8",
            "9"
        ]
    },
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7603203943314849,
                "recall": 0.7925765668311812,
                "f1-score": 0.7761134742382364,
                "support": 29582
            },
            "1": {
                "precision": 0.8077332831985963,
                "recall": 0.7771714552745033,
                "f1-score": 0.7921577063134766,
                "support": 33169
            },
            "accuracy": 0.7844337142037577,
            "macro avg": {
                "precision": 0.7840268387650406,
                "recall": 0.7848740110528423,
                "f1-score": 0.7841355902758564,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7853819568696631,
                "recall": 0.7844337142037577,
                "f1-score": 0.7845941539677012,
                "support": 62751
            },
            "roc_auc": 0.8710959918137748,
            "score": 0.8710959918137748
        },
        "val": {
            "0": {
                "precision": 0.7129066384554351,
                "recall": 0.7289075175770687,
                "f1-score": 0.7208182912154032,
                "support": 7396
            },
            "1": {
                "precision": 0.7532611370908195,
                "recall": 0.7381813796430294,
                "f1-score": 0.7456450237544159,
                "support": 8292
            },
            "accuracy": 0.7338092809790923,
            "macro avg": {
                "precision": 0.7330838877731274,
                "recall": 0.7335444486100491,
                "f1-score": 0.7332316574849096,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.734236285490405,
                "recall": 0.7338092809790923,
                "f1-score": 0.7339406309791394,
                "support": 15688
            },
            "roc_auc": 0.8193083095072056,
            "score": 0.8193083095072056
        },
        "test": {
            "0": {
                "precision": 0.7079341940857976,
                "recall": 0.7354245538128719,
                "f1-score": 0.72141758183458,
                "support": 9245
            },
            "1": {
                "precision": 0.7555466719968019,
                "recall": 0.7293777134587555,
                "f1-score": 0.7422316037504295,
                "support": 10365
            },
            "accuracy": 0.7322284548699644,
            "macro avg": {
                "precision": 0.7317404330412998,
                "recall": 0.7324011336358136,
                "f1-score": 0.7318245927925048,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7331000958475293,
                "recall": 0.7322284548699644,
                "f1-score": 0.7324189758762822,
                "support": 19610
            },
            "roc_auc": 0.8139423690776125,
            "score": 0.8139423690776125
        }
    }
}
